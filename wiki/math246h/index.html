<!doctype html><html lang=en><head><title>MATH246H :: Kandasamy Chokkalingam</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Notes from UMD's MATH246H class"><meta name=keywords content="Kandasamy Chokkalingam"><meta name=robots content="noodp"><link rel=canonical href=https://www.kandasamyc.me/wiki/math246h/><link rel=stylesheet href=https://www.kandasamyc.me/assets/style.css><link rel=stylesheet href=https://www.kandasamyc.me/assets/green.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css integrity=sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js integrity=sha384-X/XCfMm41VSsqRNQgDerQczD69XqmjOOOwYQvr/uuC+j4OPoNhVgjdGFwhvN02Ja crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<link rel=apple-touch-icon href=https://www.kandasamyc.me/img/apple-touch-icon-192x192.png><link rel="shortcut icon" href=https://www.kandasamyc.me/img/favicon/green.png><meta name=twitter:card content="summary"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="og:title" content="MATH246H"><meta property="og:description" content="Notes from UMD's MATH246H class"><meta property="og:url" content="https://www.kandasamyc.me/wiki/math246h/"><meta property="og:site_name" content="Kandasamy Chokkalingam"><meta property="og:image" content="https://www.kandasamyc.me/img/favicon/green.png"><meta property="og:image:width" content="2048"><meta property="og:image:height" content="1024"><meta property="article:published_time" content="2022-01-26 00:00:00 +0000 UTC"></head><body class=green><div class="container center"><header class=header><div class=header__inner><div class=header__logo><a href=/><div class=logo>Kandasamy Chokkalingam</div></a></div><div class=menu-trigger>menu</div></div><nav class=menu><ul class="menu__inner menu__inner--desktop"><li><a href=/>About</a></li><li><a href=/posts>Posts</a></li><li><a href=/wiki>Wiki</a></li><li><a href=/#contact>Contact</a></li></ul><ul class="menu__inner menu__inner--mobile"><li><a href=/>About</a></li><li><a href=/posts>Posts</a></li><li><a href=/wiki>Wiki</a></li><li><a href=/#contact>Contact</a></li></ul></nav></header><div class=content><div class=post><h1 class=post-title><a href=https://www.kandasamyc.me/wiki/math246h/>MATH246H</a></h1><div class=post-meta><span class=post-date>2022-01-26</span>
<span class=post-author>:: [ksam]</span></div><div class=post-content><div><h2 id=definitions-and-terminology-of-differential-equations>Definitions and Terminology of Differential Equations<a href=#definitions-and-terminology-of-differential-equations class=hanchor arialabel=Anchor>&#8983;</a></h2><h3 id=definition-of-des>Definition of DEs<a href=#definition-of-des class=hanchor arialabel=Anchor>&#8983;</a></h3><p>Some combination of one or more unknown functions with respect to one or more independent variable and those variables</p><h3 id=ordinary-des>Ordinary DEs<a href=#ordinary-des class=hanchor arialabel=Anchor>&#8983;</a></h3><p>A DE where there is only one unknown variable. A DE that is not ordinary is a partial DE</p><h3 id=order-of-des>Order of DEs<a href=#order-of-des class=hanchor arialabel=Anchor>&#8983;</a></h3><p>The highest derivative that appears in the DE.</p><h3 id=linearity>Linearity<a href=#linearity class=hanchor arialabel=Anchor>&#8983;</a></h3><p>A DE is linear if there is no function composition on the unknown functions or their derivatives.</p><h3 id=systems-of-des>Systems of DEs<a href=#systems-of-des class=hanchor arialabel=Anchor>&#8983;</a></h3><ul><li>It is a system of ODEs if there is only one unknown variable. A system that does not satisfy this is a system of PDEs.</li><li>The order of a system is the highest order of all of its equations.</li><li>A system is linear if every equation in it is linear.</li></ul><h2 id=linear-equations>Linear Equations<a href=#linear-equations class=hanchor arialabel=Anchor>&#8983;</a></h2><ul><li>DEs that are <a href=#linearity>linear</a></li></ul><h3 id=linear-normal-form>Linear Normal Form<a href=#linear-normal-form class=hanchor arialabel=Anchor>&#8983;</a></h3><p>\[\frac{dy}{dt} + \frac{q(t)}{p(t)}y = \frac{r(t)}{p(t)}\]
From now on, \(a(t) = \frac{q(t)}{p(t)}\) and \(f(t) = \frac{r(t)}{p(t)}\)</p><h4 id=homogeneous>Homogeneous<a href=#homogeneous class=hanchor arialabel=Anchor>&#8983;</a></h4><p>\[\frac{dy}{dt} + a(t)y = 0\]
By analyzing the equation, we see that this means that \(y\) is equal to its derivative. We know that \(e^x\) operates as such and we can conclude that the general solution to a Homogeneous Linear DE is:
\[y = Ce^{-A(t)}\]
where \(A(t) = \int a(t)dt\).</p><h4 id=inhomogeneous>Inhomogeneous<a href=#inhomogeneous class=hanchor arialabel=Anchor>&#8983;</a></h4><p>\[\frac{dy}{dt} + a(t)y = f(t)\]
This isn&rsquo;t quite as nice as the <a href=#homogeneous>homogeneous</a> version, but we can still solve it.</p><ul><li><p>Integrating Factor</p><p>Multiply both sides by \(e^{A(t)}\).
\[e^{A(t)}\frac{dy}{dt} + a(t)e^{A(t)}y = e^{A(t)}f(t)\]
The left side is the derivative of \(e^{A(t)}y\)
\[\frac{d}{dt}(e^{A(t)}y) = e^{A(t)}f(t)\]
This is integrating factor form. Now we can integrate both sides and solve for \(y\) to get the solution.</p></li></ul><ul><li><p>General Solution</p><p>\[y = e^{-A(t)}\int e^{A(t)}f(t)dt + Ce^{-A(t)}\]</p></li></ul><h2 id=separable-equations>Separable Equations<a href=#separable-equations class=hanchor arialabel=Anchor>&#8983;</a></h2><p>Equations that can be written in the form:
\[\frac{dy}{dt} = g(y)f(t)\]
We simply multiply both sides by \(dt\) and divide by \(g(y)\) and integrate both sides to solve. The general solution is:
\[\int \frac{1}{g(y)}dy = \int f(t)dt\]
Assuming both of these integrals are computable,
\[G(y) = F(t) + C\]
Assuming that \(G(y)\) has an inverse, \(G^{-1}(y)\),
\[y = G^{-1}(F(t) + C)\]</p><h3 id=autonomous-equations>Autonomous Equations<a href=#autonomous-equations class=hanchor arialabel=Anchor>&#8983;</a></h3><p>An equation of the form:
\[\frac{dy}{dt} = g(y)\]</p><h2 id=general-theory>General Theory<a href=#general-theory class=hanchor arialabel=Anchor>&#8983;</a></h2><h3 id=interior>Interior<a href=#interior class=hanchor arialabel=Anchor>&#8983;</a></h3><ul><li>If you can draw a rectangle around the point that is entirely container in the set</li></ul><h3 id=existence-and-uniqueness-theorem>Existence and Uniqueness Theorem<a href=#existence-and-uniqueness-theorem class=hanchor arialabel=Anchor>&#8983;</a></h3><p>For the problem \(\frac{dy}{dt} = f(t,y)\), \(y(t_1) = y_1\)</p><p>If \(f(t,y)\) is a function defined over a set \(S\) in the $ty$-plane such that</p><ol><li>\(f\) is continuous over \(S\)</li><li>\(f\) is differentiable with respect to \(y\) over \(S\)</li><li>\(\partial_yf\) is continuous over \(S\)</li></ol><p>Then for every initial time \(t_1\) and initial value \(y_1\) such that \((t_1,y_1)\) is in the interior of \(S\), there is a unique solution to the initial value problem that is defined over the largest time interval that contains the initial time and all points are in \(S\) and is smooth in that interval.</p><p>Basically, this means that given some differential equation, if it and its first-derivative of \(y\) are continuous, then there is a unique solution to the differential equation.</p><p>Because there is a unique solution to every one, two solutions can never cross. If they do, that point could be used as an initial point and produce non-unique solutions, which is not allowed.</p><h2 id=graphical-methods>Graphical Methods<a href=#graphical-methods class=hanchor arialabel=Anchor>&#8983;</a></h2><h3 id=phase-portraits-for-autonomous-equations>Phase Portraits for Autonomous Equations<a href=#phase-portraits-for-autonomous-equations class=hanchor arialabel=Anchor>&#8983;</a></h3><p>Given some <a href=#autonomous-equations>autonomous equation</a>, find the points where it is equal to 0. This is where \(g(y)\) is equal to 0. Place these points on a number line from \(-\infty\) to \(\infty\). Compute the signs for each region on this line. For each region, draw arrows pointing in the direction of signs for each region. For example, for a positive region, arrows would point right.</p><p>These arrows represent the asymptotic behavior of a solution in that region as \(t\) approaches \(\infty\). As \(t\) approaches \(-\infty\), the solution will follow the opposite direction of the arrows.</p><p>The points placed to indicate zeroes are hard boundaries. Because of <a href=#existence-and-uniqueness-theorem>Existence and Uniqueness Theorem</a>, nothing can cross these boundaries. Zeroes where the arrows on both sides point toward it are <strong>stable</strong>, while those where the arrows on both sides point away from it are <strong>unstable</strong>, and those where the arrows on both sides have conflicting directs are <strong>semi-stable</strong>.</p><p>With this information, we can draw a graph of many possible solutions. Any solution in a given \(y\) region of zeroes will follow the trends in the phase portrait. Infinitely many lines can be drawn from the given portrait but none of the lines can cross (that would violate the <a href=#existence-and-uniqueness-theorem>Existence and Uniqueness Theorem</a>).</p><h2 id=applications>Applications<a href=#applications class=hanchor arialabel=Anchor>&#8983;</a></h2><h3 id=tank-problems>Tank Problems<a href=#tank-problems class=hanchor arialabel=Anchor>&#8983;</a></h3><p>The general rule for these types of problems is:
\[\frac{dy}{dt} = \text{Rate In} - \text{Rate Out}\]
For problems that deal with some concentration \(C(t)\) of a certain mass \(S(t)\) in a volume \(V(t)\) and there is some flow \(F(t)\) both in and out
\[\frac{dS}{dt} = F_{in}C_{in} - F_{out}C_{out}\]
If the volume stays constant, \(C_{out}\) is a constant, otherwise, it should be rewritten in terms of \(S\) and \(t\) by determining an equation for \(V(t)\) from the difference in \(F_{in}\) and \(F_{out}\).</p><h2 id=numerical-methods>Numerical Methods<a href=#numerical-methods class=hanchor arialabel=Anchor>&#8983;</a></h2><h3 id=euler-s-method>Euler&rsquo;s Method<a href=#euler-s-method class=hanchor arialabel=Anchor>&#8983;</a></h3><p>One can use explicit Euler&rsquo;s method to estimate a function \(y\) at \(n\) steps of \(h\) from the initial value.
\[y_{n+1} = y_n + hf(t_n,y_n)\]</p><h2 id=exact-differential-form>Exact Differential Form<a href=#exact-differential-form class=hanchor arialabel=Anchor>&#8983;</a></h2><h3 id=formal-work>Formal Work<a href=#formal-work class=hanchor arialabel=Anchor>&#8983;</a></h3><p>We want a solution to a first order equation in the form:
\[ \frac{dy}{dx} = f(x,y)\]
We define some \(H\) to be the integral of the above equation and which defines all possible solutions \(Y\) to the differential equation:
\[H(x,y) = c\]
possibly with some initial condition \(Y(x_0)=y_0\). The question then is when can we get such an \(H\)?
Assume such a \(H\) exists and that \(Y(x)\) is a solution to the differential equation.
\[H(x,y) = H(x,Y(x))\]
Then, we take the partials with respect to both \(x\) and \(y\).
\[\partial_x H(x,Y(x)) + Y&rsquo;(x)\partial_y H(x,Y(x))\]
Solving for \(Y&rsquo;(x)\), gives us:
\[Y&rsquo;(x) = \frac{dy}{dx} = - \frac{\partial_x H(x,Y(x))}{\partial_y H(x,Y(x))}\]
Since \(y=Y(x)\) is a solution and \(\frac{dy}{dx} = f(x,y)\),
\[f(x,y) = - \frac{\partial_x H(x,y)}{\partial_y H(x,y}\]
We define some \(M(x,y) = \partial_x H(x,y)\) and some \(N(x,y) = \partial_y H(x,y)\)
\[f(x,y) = - \frac{M(x,y)}{N(x,y)}\]
Remember that we need there to be some function \(H(x,y)\) that fits our above work. Some function \(H(x,y)\) exists and the differential form is <strong>exact</strong> if \(\partial_y M(x,y) = \partial_x N(x,y)\).
If so, we can integrate either \(Mdx\) or \(Ndy\). Doing either gives us:
\[H(x,y) = g(x,y) + h\]
where \(g\) is the integral and \(h\) is some function of only the other variable. We then take the derivative of this with respect to the other variable and check it with its partial of \(H\). With that expression, we can solve for \(h\), and thereby for \(H\).</p><h3 id=informal-description>Informal Description<a href=#informal-description class=hanchor arialabel=Anchor>&#8983;</a></h3><p>Given some differential equation \(\frac{dy}{dt} = f(x,y)\) , we want to know when it has a solution.</p><p>It&rsquo;ll have a solution when we can get into some implicit form \(H(x,y) = c\). If we take the derivative of \(H\), we get some expression equal to \(f(x,y)\). This expression can be rewritten as \(f(x,y) = - \frac{M(x,y)}{N(x,y)}\) where \(M\) is the \(x\) partial of \(H\), and \(N\) is the \(y\) partial.</p><p>According to Euler, we can only have this hold when \(M_y = N_x\), that is, when the second order partials are the same. If they are, we can integrate \(M\) with respect to \(x\) and \(N\) with respect to \(y\) to solve for \(H\).</p><h3 id=integrating-factor>Integrating Factor<a href=#integrating-factor class=hanchor arialabel=Anchor>&#8983;</a></h3><p>Not all differential equations of the above form are <strong>exact</strong>. However, this does not mean they are not solveable. Some equations can multiplied through by some integrating factor \(\rho(x,y)\). The solutions to
\[M(x,y)dx + N(x,y)dy = 0\]
and
\[\rho(x,y)M(x,y)dx + \rho(x,y)N(x,y)dy = 0\]
are the same. From there, since this must be exact, the second-order partials must equal, and so:
\[\partial_y[\rho(x,y)M(x,y)] = \partial_x[\rho(x,y)N(x,y)]\]
Applying the chain rule:
\[\rho_y(x,y)M(x,y) + \rho(x,y)M_y(x,y) = \rho_x(x,y)N(x,y) + \rho(x,y)N_y(x,y)\]
This is a pretty bad equation, but we can solve it if we set either partial of \(\rho\) to 0. \(\rho\) then becomes a function of only one variable, and if we can write its partial in terms of only that variable, we can find a implicit solution.</p><p>If we set \(\rho_y\) to 0:</p><p>\[\rho(x,y)M_y(x,y) = \rho_x(x,y)N(x,y) + \rho(x,y)N_x(x,y)\]
\[\rho(x,y)M_y(x,y) - \rho(x,y)N_x(x,y) = \rho_x(x,y)N(x,y)\]
\[\rho(x,y) \frac{M_y(x,y) - N_x(x,y)}{N(x,y)} = \rho_x(x,y)\]</p><p>Similarly, if we set \(\rho_x\) to 0:</p><p>\[\rho_y(x,y)M(x,y) + \rho(x,y)M_x(x,y) = \rho(x,y)N_y(x,y)\]
\[\rho_y(x,y)M(x,y) = \rho(x,y)N_x(x,y) - \rho(x,y)M_y(x,y)\]
\[\rho_y(x,y) = \rho(x,y) \frac{N_x(x,y) - M_y(x,y)}{M(x,y)}\]</p><p>From here, you can solve for \(\rho\), and then solve \(H\) where both partial components are multiplied by \(\rho\).</p><h2 id=higher-order-linear-differential-equations>Higher Order Linear Differential Equations<a href=#higher-order-linear-differential-equations class=hanchor arialabel=Anchor>&#8983;</a></h2><h3 id=definition-and-terminology>Definition and Terminology<a href=#definition-and-terminology class=hanchor arialabel=Anchor>&#8983;</a></h3><p>Every \(n^th\) order linear DE can be written in the form:
\[\frac{d^ny}{dt^n}+a_1(t)\frac{d^{n-1}y}{dt^{n-1}}+&mldr;+a_{n-1}(t)\frac{dy}{dt}+a_n(t)y=f(t)\]</p><p>To get a specific solution for an \(n^th\) order equation, we need \(n\) initial conditions because repeated derivatives lose more and more information:
\[Y(t_1)=y_0, Y^{(1)}(t_1)=y_1, &mldr;, Y^{(n-1)}(t_1)=y_{n-1}\]</p><h4 id=coefficient-functions>Coefficient Functions<a href=#coefficient-functions class=hanchor arialabel=Anchor>&#8983;</a></h4><p>The functions \(a_1(t)&mldr;a_n(t)\) are called coefficient functions. When all of the coefficient functions do not vary with \(t\), the equation is said to be <strong>constant coefficient</strong>.</p><h4 id=forcing-functions>Forcing Functions<a href=#forcing-functions class=hanchor arialabel=Anchor>&#8983;</a></h4><p>The function \(f(t)\) is called the forcing function. When the forcing function is 0, then the equation is said to be <strong>homogeneous</strong>. Otherwise, it is said to be <strong>inhomogeneous</strong></p><h3 id=linear-differential-operator>Linear Differential Operator<a href=#linear-differential-operator class=hanchor arialabel=Anchor>&#8983;</a></h3><p>We can also define a differential operator \(\mathbb{L}\) that is:
\[\mathbb{L} = D^n+D^{n-1}a_1(t) + &mldr; + D^1a_{n-1}(t) + a_n(t)\]
where \(D = \frac{d}{dt}\). In essence, we factor out a \(y\) to make \(\mathbb{L}\) function-agnostic. Therefore, our initial equation can be written as:
\[\mathbb{L}y = f(t)\]
\(\mathbb{L}\) is linear, meaning applying it to a linear combination of functions is the same as applying it to each one. That is:
\[\mathbb{L}(c_1y_1+c_2y_2) = \mathbb{L}c_1y_1 + \mathbb{L}c_2y_2\]</p><h3 id=superposition-principle>Superposition Principle<a href=#superposition-principle class=hanchor arialabel=Anchor>&#8983;</a></h3><p>Given some \(n^th\) order linear homogeneous differential equation, there are generally \(n\) solutions \(Y_1(t), Y_2(t) &mldr; Y_{n-1}(t)\). If each of these are solutions, then any linear combination of them are. This is because \(\mathbb{L}\) is linear.</p><h3 id=wronskian>Wronskian<a href=#wronskian class=hanchor arialabel=Anchor>&#8983;</a></h3><p>We can check if some set of possible solutions \(Y_1(t),Y_2(t)&mldr;Y_{n-1}(t)\) are independent over some interval if the Wronskian is not 0.
\[\mathbb{W} = \det \begin{vmatrix} Y_1(t) & Y_2(t) & &mldr; & Y_n(t) \\ Y^(1)_1(t) & Y^(1)_2(t) & &mldr; & Y^(1)_n(t) \\ \vdots & \vdots & \ddots & \vdots \\ Y^{(n-1)}_1(t) & Y^{(n-1)}_2(t) & &mldr; & Y^{(n-1)}_n(t) \end{vmatrix}\]
Anywhere \(\mathbb{W}\) is not 0, the solutions are independent.</p><h2 id=homogenous-higher-order-linear-des>Homogenous Higher-Order Linear DEs<a href=#homogenous-higher-order-linear-des class=hanchor arialabel=Anchor>&#8983;</a></h2><p>These are <a href=#homogeneous>Homogeneous</a>, <a href=#linear-equations>Linear Equations</a>.</p><h3 id=characteristic-polynomial>Characteristic Polynomial<a href=#characteristic-polynomial class=hanchor arialabel=Anchor>&#8983;</a></h3><p>This applies to homogenous, constant coefficient linear differential equations.
Expressing \(\mathbb{L}\) as a function of \(D\), we have:
\[p(D)\]
The characteristic polynomial is the function \(p(z)\), where \(z\) is some variable. Every root of this polynomial corresponds to a solution of \(\mathbb{L}y=0\).</p><h4 id=distinct-real-roots>Distinct Real Roots<a href=#distinct-real-roots class=hanchor arialabel=Anchor>&#8983;</a></h4><p>A root \(r\) corresponds to the solution \(e^{rt}\) if the root is distinct.</p><h4 id=repeated-real-roots>Repeated Real Roots<a href=#repeated-real-roots class=hanchor arialabel=Anchor>&#8983;</a></h4><p>A root \(r\) with multiplicity \(m\) corresponds to the solutions \(e^{rt}, te^{rt}, \dots, t^{m-1}e^{rt}\).</p><h4 id=complex-roots>Complex Roots<a href=#complex-roots class=hanchor arialabel=Anchor>&#8983;</a></h4><p>A root \(r \pm is\) corresponds to the solutions \(e^{rt}cos(st)\) and \(e^{rt}sin(st)\)</p><p>If it has multiplicity m, then it corresponds to the solutions \(e^{rt}cos(st), te^{rt}cos(st), \dots, t^{m-1}e^{rt}cos(st)\) and \(e^{rt}sin(st), te^{rt}sin(st), \dots, t^{m-1}e^{rt}sin(st)\)</p><h2 id=nonhomogeneous-higher-order-linear-des>Nonhomogeneous Higher-Order Linear DEs<a href=#nonhomogeneous-higher-order-linear-des class=hanchor arialabel=Anchor>&#8983;</a></h2><p>These are <a href=#homogeneous>Nonhomogeneous</a>, <a href=#linear-equations>Linear Equations</a>.</p><h3 id=general-theory>General Theory<a href=#general-theory class=hanchor arialabel=Anchor>&#8983;</a></h3><p>Since the <a href=#linear-differential-operator>linear differential operator</a> is linear, a linear combination of functions applied to it is the same as apply \(\mathbb{L}\) individually. We can exploit this fact to solve nonhomogeneous DEs.</p><p>If \(Y_P(t)\) is a solution to some nonhomogeneous DE \(\mathbb{L}(t)y = f(t)\) and \(Y_H(t)\) is a solution to the associated homogeneous equation \(\mathbb{L}(t)y = 0\), then \(Y(t) = Y_H(t)+Y_P(t)\) is also a solution of \(\mathbb{L}(t)y = f(t)\). This is because applying \(\mathbb{L}(t)\) individually makes the \(Y_H(t)\) component zero, which the \(Y_P(t)\) component is still \(f(t)\)</p><p>Note that \(Y(t)\) differs from \(Y_P(t)\) in that it is a general solution to the DE. \(Y_P(t)\) is only a particular one. Therefore, to find a general solution, we need a homogeneous solution (which we know how to calculate) and a particular solution (Finding Particular Solutions).</p><h3 id=finding-particular-solutions>Finding Particular Solutions<a href=#finding-particular-solutions class=hanchor arialabel=Anchor>&#8983;</a></h3><h4 id=characteristic-form>Characteristic Form<a href=#characteristic-form class=hanchor arialabel=Anchor>&#8983;</a></h4><p>\[f(t) = (\alpha_0t^d + \alpha_1t^{d-1} + \dots + \alpha_d)e^{\mu t}cos(\nu t) + (\beta_0t^d + \beta_1t^{d-1} + \dots + \beta_d)e^{\mu t}sin(\nu t)\]
where \(d\) is a nonnegative integer, \(\alpha_0 \dots \alpha_d\) and \(\beta_0 \dots \beta_d\) are real coefficients, and \(\mu\) \(\nu\) are other real numbers. Assume that either \(\alpha_0 \neq 0\) or \(\nu\beta_0 \neq 0\). This ensures that there is always a nonzero \(t_d\) term (the \(\nu\) comes into the latter term because \(sin(0)\) is always 0).</p><ul><li><p>Degree</p><p>This is the nonnegative integer \(d\). When \(d \neq 0\) then \(f(t)\) has positive degree.</p></li></ul><ul><li><p>Characteristic</p><p>This is the complex number \(\mu + i\nu\). When \(\nu = 0\), \(f(t)\) has real characteristic form, otherwise it has complex characteristic form.</p></li></ul><ul><li><p>Multiplicity</p><p>This the multiplicity of the <a href=#characteristic>characteristic</a> as a root of the associated <a href=#characteristic-polynomial>characteristic polynomial</a> \(p(z)\). It is 0 if it is not a root.</p></li></ul><h4 id=undetermined-coefficients>Undetermined Coefficients<a href=#undetermined-coefficients class=hanchor arialabel=Anchor>&#8983;</a></h4><p>The particular solution has the form:
\[Y_P(t) = (A_0t^{m+d} + A_1t^{m+d-1} + \dots + A_dt^{m})e^{\mu t}cos(\nu t) + (B_0t^{m+d} + B_1t^{m+d-1} + \dots + B_dt^m)e^{\mu t}sin(\nu t)\]</p><ol><li>Construct \(Y_P(t)\) using the above formula and combine like terms</li><li>Plug that into \(\mathbb{L}Y_P(t) = f(t)\) and match the terms on either side (partial fraction decomposition style)</li><li>Solve the system for the unknowns</li></ol><h4 id=key-identities>Key Identities<a href=#key-identities class=hanchor arialabel=Anchor>&#8983;</a></h4><ol><li>Write down the Key Identity \(\mathbb{L}(e^{zt}) = p(z)e^{zt}\) and its derivatives with respect to \(z\) up through the \(m+d\) derivative</li><li>Evaluate each one at \(z=\mu + i\nu\)</li><li>Solve for the coefficients of the linear combination of the evaluations whose real part is equal to the forcing function</li></ol><p>The derivatives of the Key Identity follow Pascal&rsquo;s triangle:
\[\mathbb{L}(e^{zt}) = p(z)e^{zt}\]
\[\mathbb{L}(te^{zt}) = p&rsquo;(z)e^{zt} + p(z)te^{zt}\]
\[\mathbb{L}(t^2e^{zt}) = p&rsquo;&rsquo;(z)e^{zt} + 2p&rsquo;(z)te^{zt} + p(z)t^2e^{zt}\]
Generally, the \(n^{th}\) derivative is:
\[\mathbb{L}(t^ne^{zt}) = p^{(n)}(z)e^{zt} + c_1p^{(n-1)}(z)te^{zt} + \dots + c_{n-1}p^{(1)}(z)t^{n-1}e^{zt} + p(z)t^ne^{zt}\]</p><h4 id=variation-of-parameters>Variation of Parameters<a href=#variation-of-parameters class=hanchor arialabel=Anchor>&#8983;</a></h4><p>Both <a href=#undetermined-coefficients>Undetermined Coefficients</a> and <a href=#key-identities>Key Identities</a> only work for constant coefficient equations. Variation of Parameters works for equation with variable coefficient equations as well.</p><p>First, let&rsquo;s examine the second order case and then generalize.</p><ol><li>We seek a solution to the equation \(y&rsquo;&rsquo; + a_1(t)y&rsquo; + a_2(t)y = f(t)\) of the form:
\[y = u_1(t)Y_1(t) + u_2(t)Y_2(t)\]</li><li>We write down a system of linear equations to solve:
\[u&rsquo;_1(t)Y_1(t) + u&rsquo;_2(t)Y_2(t) = 0\]
\[u&rsquo;_1(t)Y&rsquo;_1(t) + u&rsquo;_2(t)Y&rsquo;_2(t) = f(t)\]</li><li>Solve the system for expressions for \(u&rsquo;_1(t)\) and \(u&rsquo;_2(t)\).</li><li>Evaluate the expressions to find \(u_{1P}(t)\) and \(u_{2P}(t)\) and therefore \(u_1(t) = u_{1P} + c_1\) and \(u_2(t) = u_{2P}(t) + c_2\)</li><li>The general solution is therefore \(u_1(t)Y_1(t) + u_2(t)Y_2(t)\) and using the initial values, you can solve for \(c_1\) and \(c_2\)</li></ol><h3 id=laplace-transforms>Laplace Transforms<a href=#laplace-transforms class=hanchor arialabel=Anchor>&#8983;</a></h3><p>The Laplace transform turns a differential equation with constant coefficients into a algebraic equation.</p><p>To solve an IVP, we apply the Laplace transform to the initial problem, solve the transformed equation, and apply the inverse Laplace transform to find the solution</p><h4 id=definition>Definition<a href=#definition class=hanchor arialabel=Anchor>&#8983;</a></h4><p>The Laplace transform of a function \(f(t)\) is:</p><p>\[\mathcal{L}[f](s) = \int_0^\infty e^{-st}f(t) dt\]</p><p>We can evaluate this by saying that:</p><p>\[\mathcal{L}[f](s) = \lim_{T \to \infty} \int_0^T e^{-st}f(t) dt\]</p><h4 id=properties>Properties<a href=#properties class=hanchor arialabel=Anchor>&#8983;</a></h4><ul><li><p>Linearity</p><p>\(\mathcal{L}[f+g](s) = \mathcal{L}[f](s) + \mathcal{L}[g](s)\) and \(\mathcal{L}[cf](s) = c\mathcal{L}[f](s)\)</p></li></ul><ul><li><p>Exponentials and Translation</p><p>An exponential in \(t\) becomes a translation in \(s\) and vice versa. That is:</p><p>\[\mathcal{L}[e^{at}f](s) = \mathcal{L}[f](s-a)\]</p></li></ul><ul><li><p>Derivatives and Multiplication</p><p>A derivative with respect to \(t\) becomes a multiplication by \(s\). That is:</p><p>\[\mathcal{L}[f&rsquo;](s) = s\mathcal{L}[f](s) - f(0)\]</p></li></ul><h4 id=usage>Usage<a href=#usage class=hanchor arialabel=Anchor>&#8983;</a></h4><ol><li>Given an IVP \(\mathbb{L}y = f(t)\), apply the Laplace transform to get \(\mathcal{L}[\mathbb{L}y](s) = \mathcal{L}[f](s)\)</li><li>Solve for \(Y(s)\)</li><li>Apply the inverse Laplace transform: \(\mathcal{L}^{-1}[Y](s)\)</li></ol><ul><li><p>Piecewise Functions</p><p>Say we have a forcing function \(f(t)\) that is piecewise:
\[f(t) = \begin{cases} f_0(t) \quad &1 \leq t \lt c\\ 0 \quad &t \geq c\end{cases}\]</p><p>How do we apply the Laplace tranform? We can use the Heaviside Function \(u(t)\) to rewrite the piecewise function as a regular function. The Heaviside function is defined as:
\[u(t-c) = \begin{cases} 0 \quad &t \lt 0\\ 1 \quad &t \geq c\end{cases}\]</p><p>Therefore, we can rewrite our piecewise function as intervals multiplied by the heaviside function with an appropriate \(c\), and turn off the previous interval by subtracting from the next heaviside function.</p><p>\[f(t) = f_0(t) + u(t-c)h(t)\]</p><p>Where \(h(t) = 1-f_0(t)\). However, note that to apply the Laplace Transform, the rule specifies that the form must be \(u(t-c)h(t-c)\). Therefore, we rewrite our forcing term as:</p><p>\[f(t) = f_0(t) + u(t-c)j(t-c)\]</p><p>where \(j(t) = h(t+c)\). This does not affect the expression of the forcing function but correctly determines how we apply the Laplace transform to it.</p></li></ul><h2 id=first-order-systems-of-odes>First-Order Systems of ODEs<a href=#first-order-systems-of-odes class=hanchor arialabel=Anchor>&#8983;</a></h2><h3 id=matrix-forms>Matrix Forms<a href=#matrix-forms class=hanchor arialabel=Anchor>&#8983;</a></h3><ul><li>Say we have some system of first order equations with dimension \(n\):
\[\begin{matrix} \frac{dx_1}{dt} = a_{11}(t)x_1 + a_{12}(t)x_2 + \dots + a_{1n}(t)x_n + f_1(t)\\ \frac{dx_2}{dt} = a_{21}(t)x_1 + a_{22}(t)x_2 + \dots + a_{2n}(t)x_n + f_2(t)\\ \vdots \\ \frac{dx_2}{dt} = a_{n1}(t)x_1 + a_{n2}(t)x_2 + \dots + a_{nn}(t)x_n + f_n(t)\end{matrix}\]</li><li>We can rewrite this more compactly as:
\[\frac{d{\bf x}}{dt} = {\bf A}(t){\bf x} + {\bf f}(t)\]</li><li>We can specify an initial condition with:
\[{\bf x}(t_I) = {\bf x}&rsquo;\]</li></ul><h3 id=fundamental-matrices>Fundamental Matrices<a href=#fundamental-matrices class=hanchor arialabel=Anchor>&#8983;</a></h3><ul><li>If \({\bf x}_1(t), {\bf x}_2(t), \dotsb, {\bf x}_n(t)\) are solutions, then the fundamental matrix for the system is:</li></ul><p>\[\Psi(t) = ({\bf x}_1(t) \quad {\bf x}_2(t) \quad \dotsb \quad {\bf x}_n(t))\]</p><ul><li>\(\Psi&rsquo; = A(t)\Psi\), in fact a general solution of the system is \({\bf x}(t) = \Psi(t){\bf c}\)</li></ul><h3 id=natural-fundamental-matrices>Natural Fundamental Matrices<a href=#natural-fundamental-matrices class=hanchor arialabel=Anchor>&#8983;</a></h3><ul><li>Using the fact that a <a href=#fundamental-matrices>Fundamental Matrix</a> is a general solution, the natural fundamental matrix is the solution to the corresponding IVP
\[\Phi(t) = \Psi(t)\Psi(t_I)^-1\]
\[\Phi&rsquo; = {\bf A}(t)\Phi, \quad \Phi(t_I) = I\]</li></ul><h3 id=eigen-methods>Eigen Methods<a href=#eigen-methods class=hanchor arialabel=Anchor>&#8983;</a></h3><h4 id=eigenvalue>Eigenvalue<a href=#eigenvalue class=hanchor arialabel=Anchor>&#8983;</a></h4><ul><li>To find the eigenvalues for a matrix \({\bf A}\) solve the polynomial:
\[p_{\bf A}(z) = det({\bf A}-z{\bf I}) = z^2 - tr({\bf A}) + det({\bf A})\]</li></ul><h4 id=eigenvector>Eigenvector<a href=#eigenvector class=hanchor arialabel=Anchor>&#8983;</a></h4><ul><li>To find the eigenvectors for a given eigenvalue \(\lambda\) and a matrix \({\bf A}\), find the values of the vector \({\bf v}\) such that:
\[({\bf A} - \lambda{\bf I}){\bf v} = 0\]</li><li>By the Cayley-Hamilton Theorem, for a 2x2 matrix, any nonzero column of \({\bf A}-\lambda_1{\bf I}\) is an eigenvector for \(\lambda_2\) and any nonzero column of \({\bf A}-\lambda_2{\bf I}\) is an eigenvector for \(\lambda_2\)<ul><li>For eigenvalues that are complex conjugates of each other, this method works, but it also holds that if \(\lambda_1\) and \(\lambda_2\) are complex conjugates and \({\bf v}_1\) is the eigenvector association with \(\lambda_1\), then an eigenvector associated with \(\lambda_2\) is the complex conjugate of \({\bf v}_1\)</li><li>This method works for an eigenvalue with a multiplicity greater than 1 as well</li></ul></li></ul><h4 id=eigensolutions>Eigensolutions<a href=#eigensolutions class=hanchor arialabel=Anchor>&#8983;</a></h4><ul><li>If \((\lambda, {\bf v})\) is an eigenpair for \({\bf A}\), then a solution is \(x^{\lambda t}{\bf v}\)</li><li>If \(\lambda\) is not real, then two solutions are \(Re(e^{\lambda t}{\bf v})\) and \(Im(e^{\lambda t}{\bf v})\)</li><li>If \(\lambda\) is the only eigenvalue for \({\bf A}\), then two solutions exists: \({\bf x}_1(t) = e^{\lambda t}{\bf v}\) and \({\bf x}_2(t) = e^{\lambda t}{\bf w} + te^{\lambda t}({\bf A}-\lambda{\bf I}){\bf w}\) where \({\bf w}\) is any vector that is not a scalar multiple of \({\bf v}\)<ul><li>The easiest way to get \({\bf w}\) is to make an entry in \({\bf v}\) 0</li></ul></li><li>\(e^{t{\bf A}}\) is a natural fundamental matrix and therefore \(e^{t{\bf A}} = \Psi(t)\Psi(0)^{-1}\)</li></ul><h3 id=linear-planar-systems>Linear Planar Systems<a href=#linear-planar-systems class=hanchor arialabel=Anchor>&#8983;</a></h3><h4 id=general-theory>General Theory<a href=#general-theory class=hanchor arialabel=Anchor>&#8983;</a></h4><p>A homogenous linear planar system has the form:
\[\frac{d}{dt}\begin{pmatrix}x \\ y\end{pmatrix} = {\bf A}\begin{pmatrix}x \\y\end{pmatrix}\]
This traces out a curve \((x(t),y(t))\) in the \(xy\text{-plane}\)</p><p>If the matrix \({\bf A}\) has a real eigenpair \((\lambda, {\bf v})\), then it has a solution \({\bf x}(t) = ce^{\lambda t}{\bf v}\). If \(\lambda \gt 0\), then \({\bf x} = c{\bf v}\) has 3 orbits, the stationary point when \(c=0\), and the other two half lines moving away from it. If \(\lambda \lt 0\), then it has 3 orbits, the stationary point when \(c=0\) and the other two half lines moving toward it. If \(\lambda = 0\), then every point is a stationary point.</p><h4 id=two-real-eigenvalues>Two Real Eigenvalues<a href=#two-real-eigenvalues class=hanchor arialabel=Anchor>&#8983;</a></h4><ul><li>Two real eigenpairs are need to sketch</li></ul><ul><li><p>Saddle</p><ul><li>\(\lambda_1 \lt 0 \lt \lambda 2\)</li></ul><figure class=center><img src=/img/math246h-saddle.png><figcaption class=center>Saddle</figcaption></figure></li></ul><ul><li><p>Nodal Sink</p><ul><li>\(\lambda_1 \lt \lambda_2 \lt 0\)</li></ul><figure class=center><img src=/img/math246h-nodal-sink.png><figcaption class=center>Nodal Sink</figcaption></figure></li></ul><ul><li><p>Nodal Source</p><ul><li>\(0 \lt \lambda_1 \lt \lambda_2\)</li></ul><figure class=center><img src=/img/math246h-nodal-source.png><figcaption class=center>Nodal Source</figcaption></figure></li></ul><ul><li><p>Spinal Sink</p><ul><li>\(\lambda_1 \lt \lambda_2 = 0\)</li></ul><figure class=center><img src=/img/math246h-spinal-sink.png><figcaption class=center>Spinal Sink</figcaption></figure></li></ul><ul><li><p>Spinal Source</p><ul><li>\(0 = \lambda_1 \lt \lambda_2\)</li></ul><figure class=center><img src=/img/math246h-spinal-source.png><figcaption class=center>Spinal Source</figcaption></figure></li></ul><h4 id=one-real-eigenvalue>One Real Eigenvalue<a href=#one-real-eigenvalue class=hanchor arialabel=Anchor>&#8983;</a></h4><ul><li><p>Radial Sink</p><ul><li>\(\lambda \lt 0\) and \({\bf A} = c{\bf I}\)</li></ul><figure class=center><img src=/img/math246h-radial-sink.png><figcaption class=center>Radial Sink</figcaption></figure></li></ul><ul><li><p>Radial Source</p><ul><li>\(\lambda \gt 0\) and \({\bf A} = c{\bf I}\)</li></ul><figure class=center><img src=/img/math246h-radial-source.png><figcaption class=center>Radial Source</figcaption></figure></li></ul><ul><li><p>Null</p><ul><li>\(\lambda = 0\) and \({\bf A} = c{\bf I}\)</li></ul></li></ul><ul><li><p>Twist Sink</p><ul><li>\(\lambda \lt 0\) and \({\bf A} \neq c{\bf I}\)</li><li>Clockwise if \(a_{21} \lt 0\), Counterclockwise if \(a_{21} \gt 0\)</li></ul><div style=display:flex;justify-content:space-around><figure style=display:inline-block><img src=/img/math246h-twist-sink-cw.png><figcaption class=center>Clockwise Twist Sink</figcaption></figure><figure style=display:inline-block><img src=/img/math246h-twist-sink-cc.png><figcaption class=center>Counterclockwise Twist Sink</figcaption></figure></div></li></ul><ul><li><p>Twist Source</p><ul><li>\(\lambda \gt 0\) and \({\bf A} \neq c{\bf I}\)</li><li>Clockwise if \(a_{21} \lt 0\), Counterclockwise if \(a_{21} \gt 0\)</li></ul><div style=display:flex;justify-content:space-around><figure style=display:inline-block><img src=/img/math246h-twist-source-cw.png><figcaption class=center>Clockwise Twist Source</figcaption></figure><figure style=display:inline-block><img src=/img/math246h-twist-source-cc.png><figcaption class=center>Counterclockwise Twist Source</figcaption></figure></div></li></ul><ul><li><p>Shear</p><ul><li>\(\lambda = 0\) and \({\bf A} \neq c{\bf I}\)</li><li>Clockwise if \(a_{21} \lt 0\), Counterclockwise if \(a_{21} \gt 0\)</li></ul><div style=display:flex;justify-content:space-around><figure style=display:inline-block><img src=/img/math246h-shear-cw.png><figcaption class=center>Clockwise Shear</figcaption></figure><figure style=display:inline-block><img src=/img/math246h-shear-cc.png><figcaption class=center>Counterclockwise Shear</figcaption></figure></div></li></ul><h4 id=complex-conjugate-pair-of-eigenvalues>Complex Conjugate Pair of Eigenvalues<a href=#complex-conjugate-pair-of-eigenvalues class=hanchor arialabel=Anchor>&#8983;</a></h4><ul><li><p>Spiral Sink</p><ul><li>\(\text{Re}(\lambda) \lt 0\)</li><li>Clockwise if \(a_{21} \lt 0\), Counterclockwise if \(a_{21} \gt 0\)</li></ul><div style=display:flex;justify-content:space-around><figure style=display:inline-block><img src=/img/math246h-spiral-sink-cw.png><figcaption class=center>Clockwise Spiral Sink</figcaption></figure><figure style=display:inline-block><img src=/img/math246h-spiral-sink-cc.png><figcaption class=center>Counterclockwise Spiral Sink</figcaption></figure></div></li></ul><ul><li><p>Spiral Source</p><ul><li>\(\text{Re}(\lambda) \gt 0\)</li><li>Clockwise if \(a_{21} \lt 0\), Counterclockwise if \(a_{21} \gt 0\)</li></ul><div style=display:flex;justify-content:space-around><figure style=display:inline-block><img src=/img/math246h-spiral-sink-cw.png><figcaption class=center>Clockwise Spiral Source</figcaption></figure><figure style=display:inline-block><img src=/img/math246h-spiral-sink-cc.png><figcaption class=center>Counterclockwise Twist Source</figcaption></figure></div></li></ul><ul><li><p>Center</p><ul><li>\(\text{Re}(\lambda) = 0\)</li><li>Clockwise if \(a_{21} \lt 0\), Counterclockwise if \(a_{21} \gt 0\)</li></ul><div style=display:flex;justify-content:space-around><figure style=display:inline-block><img src=/img/math246h-center-cw.png><figcaption class=center>Clockwise Center</figcaption></figure><figure style=display:inline-block><img src=/img/math246h-center-cc.png><figcaption class=center>Counterclockwise Center</figcaption></figure></div></li></ul></div></div></div></div><footer class=footer><div class=footer__inner><div class="copyright copyright--user"><span>Â©2022 Kandasamy Chokkalingam</span>
<span>:: Based on <a href=https://twitter.com/panr>panr's</a> Terminal theme</aspan></div></div></footer><script src=https://www.kandasamyc.me/assets/main.js></script>
<script src=https://www.kandasamyc.me/assets/prism.js></script></div></body></html>